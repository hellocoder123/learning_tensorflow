{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "Iter 0 Testing Accuracy 0.9517 ,Training Accuracy 0.95754546\n",
      "Iter 1 Testing Accuracy 0.9655 ,Training Accuracy 0.97481817\n",
      "Iter 2 Testing Accuracy 0.9721 ,Training Accuracy 0.9826546\n",
      "Iter 3 Testing Accuracy 0.9732 ,Training Accuracy 0.98627275\n",
      "Iter 4 Testing Accuracy 0.9768 ,Training Accuracy 0.9898546\n",
      "Iter 5 Testing Accuracy 0.9775 ,Training Accuracy 0.99252725\n",
      "Iter 6 Testing Accuracy 0.9785 ,Training Accuracy 0.9930182\n",
      "Iter 7 Testing Accuracy 0.9793 ,Training Accuracy 0.9944364\n",
      "Iter 8 Testing Accuracy 0.9775 ,Training Accuracy 0.9950909\n",
      "Iter 9 Testing Accuracy 0.9801 ,Training Accuracy 0.9958\n",
      "Iter 10 Testing Accuracy 0.9787 ,Training Accuracy 0.99594545\n",
      "Iter 11 Testing Accuracy 0.9812 ,Training Accuracy 0.9964727\n",
      "Iter 12 Testing Accuracy 0.9817 ,Training Accuracy 0.9967818\n",
      "Iter 13 Testing Accuracy 0.9814 ,Training Accuracy 0.99716365\n",
      "Iter 14 Testing Accuracy 0.9808 ,Training Accuracy 0.99709094\n",
      "Iter 15 Testing Accuracy 0.9815 ,Training Accuracy 0.99734545\n",
      "Iter 16 Testing Accuracy 0.9799 ,Training Accuracy 0.9968909\n",
      "Iter 17 Testing Accuracy 0.9817 ,Training Accuracy 0.9974909\n",
      "Iter 18 Testing Accuracy 0.9821 ,Training Accuracy 0.9976364\n",
      "Iter 19 Testing Accuracy 0.982 ,Training Accuracy 0.9976364\n",
      "Iter 20 Testing Accuracy 0.9816 ,Training Accuracy 0.99767274\n"
     ]
    }
   ],
   "source": [
    "#载入数据集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)\n",
    "\n",
    "#设置批次的大小\n",
    "batch_size = 100\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "lr = tf.Variable(0.001,dtype=tf.float32)\n",
    "\n",
    "#构建神经网络结构\n",
    "# W = tf.Variable(tf.zeros([784,10]))\n",
    "# b = tf.Variable(tf.zeros([10]))\n",
    "# prediction = tf.nn.softmax(tf.matmul(x,W)+b)\n",
    "\n",
    "Weight_L1 = tf.Variable(tf.truncated_normal([784,500],stddev=0.1))\n",
    "baises_L1 = tf.Variable(tf.zeros([500])+0.1)\n",
    "Wx_plus_b_L1 = tf.matmul(x,Weight_L1)+baises_L1\n",
    "L1 = tf.nn.tanh(Wx_plus_b_L1)\n",
    "L1_drop = tf.nn.dropout(L1,keep_prob)\n",
    "\n",
    "Weight_L2 = tf.Variable(tf.truncated_normal([500,300],stddev=0.1))\n",
    "baises_L2 = tf.Variable(tf.zeros([300])+0.1)\n",
    "Wx_plus_b_L2 = tf.matmul(L1_drop,Weight_L2)+baises_L2\n",
    "L2 = tf.nn.tanh(Wx_plus_b_L2)\n",
    "L2_drop = tf.nn.dropout(L2,keep_prob)\n",
    "\n",
    "Weight_L3 = tf.Variable(tf.truncated_normal([300,10],stddev=0.1))\n",
    "baises_L3 = tf.Variable(tf.zeros([10])+0.1)\n",
    "Wx_plus_b_L3 = tf.matmul(L2_drop,Weight_L3)+baises_L3\n",
    "prediction = tf.nn.tanh(Wx_plus_b_L3)\n",
    "\n",
    "\n",
    "#二次代价函数\n",
    "# loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))\n",
    "#梯度下降优化器\n",
    "# train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epcho in range(21):\n",
    "        sess.run(tf.assign(lr,0.001*(0.95**(epcho))))\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys,keep_prob:1.0})\n",
    "        \n",
    "        test_acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels,keep_prob:1.0})\n",
    "        train_acc = sess.run(accuracy,feed_dict={x:mnist.train.images,y:mnist.train.labels,keep_prob:1.0})\n",
    "        print(\"Iter \"+str(epcho)+\" Testing Accuracy \"+str(test_acc)+\" ,Training Accuracy \"+str(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
